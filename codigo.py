# -*- coding: utf-8 -*-
"""Codigo.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Z5zaHs5YXt8GwKd2ciMrMUn_Q66GqLhm
"""

!pip install detect
!pip install langdetect
!python -m spacy download es_core_news_sm
import es_core_news_sm
import pandas as pd 
import numpy as np
import re
import nltk
import spacy
from nltk.corpus import stopwords
from numpy import array
from keras_preprocessing.sequence import pad_sequences
from keras.models import Sequential
from keras.layers.core import Activation, Dropout, Dense
from keras.layers import Flatten, Conv1D, LSTM, GlobalMaxPooling1D
from keras.layers import Embedding
from sklearn.model_selection import train_test_split
from keras.preprocessing.text import Tokenizer
import matplotlib.pyplot as plt
import os
from langdetect import detect
from tensorflow.keras import Sequential, layers, preprocessing
from google.colab import drive
drive.mount('/content/gdrive')

# Importación de módulos para diseñar la red neuronal
from tensorflow.keras import Sequential
from tensorflow.keras import layers
from tensorflow.keras import preprocessing
from tensorflow.keras.layers import Dropout

os.chdir("/content/gdrive/My Drive/")

df=pd.read_csv('2_Labelled data.csv',encoding='latin-1')

import nltk
nltk.download('stopwords')
pln_es = spacy.load('es_core_news_sm')
stop_words = nltk.corpus.stopwords.words('spanish')

def edad1(t):
    doc = pln_es(t)
    y=[]
    no_considerar=["innovación","brindando", "mercado", "trayectoria",  "experiencia",
                   "hace más de","revolucionando","días", "con mas de","soluciones","historia","ayudando ","mbps","inmobiliaria"
                   ,"empresa","industria","desde","hace"]
    for token in doc:
        if token.pos_ == "NUM" and len(token.text) == 2 and (token.head.text=="edad" or token.head.text=="años"):
            # append the word three words before and after token.pos_
            t=doc[token.i-4:token.i+4]
            t2=t.text.split()
            if any(word in t2 for word in no_considerar):
                t2=[]
            else:
                y.append(t)
        # drop duplicates in y
        y = list(dict.fromkeys(y))
    return y

def limpia(texto):
    quitar=stopwords.words('spanish')
    r2 = r'[^\w\s\d]'
    texto = ' '.join([palabra for palabra in texto.split() if palabra not in quitar])
    texto = re.sub(r'\s+', ' ', texto)
    texto = re.sub(r2, ' ', texto)
    texto = texto.lower()
    return texto


df['cont_limp'] = df['contenido'].apply(lambda x: limpia(x))

df.at[24215 ,"cont_limp"]

import spacy

nlp = spacy.load("es_core_news_sm")

y=pd.DataFrame()
for i in range(0,45000):

  inter=list()
  if len(edad1(df.at[i,"cont_limp"]))==0:
    inter.append(0)
    inter.append(0)
  else:
    orac=nlp(str(edad1(df.at[i,"cont_limp"])[0]))
    for w in orac:
        if w.pos_=="NUM":
          try:
            a=w.text
            a=int(a)
            if 15<=a<=69:
              inter.append(a)
          except ValueError:
            a
  inter=np.array([inter])
  inter=pd.DataFrame(inter)
  y=y.append(inter)

y.columns=["a","b"]
#y = y.reset_index()
#y=y.drop(['index'], axis=1)

#funciones de rangos
def rangos1(row):
  result=0
  if (16<= row["a"] and row["b"] <=20) or (16<= row["a"] <=20): # 16-20
    result=1
  return result
y["16-20"] = y.apply(rangos1, axis=1)

def rangos2(row):
  result=0
  if (21<=row["a"]<=35 or 21<=row["b"]<=35) or (21<=row["a"] and row["b"]<=35) or (row["a"]<=20 and 35<=row["b"]): # 21-35
    result=1
  return result
y["21-35"] = y.apply(rangos2, axis=1)

def rangos3(row):
  result=0
  if (36<= row["b"] <= 69) or (36<=row["a"] and row["b"]<=69): # 36-69
    result=1
  return result
y["36-69"] = y.apply(rangos3, axis=1)

#y.to_csv("edadesr.csv")
#y=pd.read_csv('edadesr.csv',encoding='latin-1')
#y=y.drop(['Unnamed: 0'], axis=1)
#y['contenido'] = df['contenido']
y=y.fillna(69)

#prueba
valor=34543
print(edad1(df.at[valor,"cont_limp"]))
orac=nlp(str(edad1(df.at[valor,"cont_limp"])[0]))
print(orac.text)
for w in orac:
        if w.pos_=="NUM":
          print(w.text)
          a=w.text
          try:
            a=int(a)
          except ValueError:
            a

a=pd.DataFrame()
# extraer ingresos rango y un valor solo
def regex_money(text):

    money_range = re.findall(r'\$\s?\d+\s?-\s?\d+', text)
    if money_range:
        return money_range
    else:
        money_single = re.findall(r'\$\s?\d+', text)
        if money_single:
            return money_single
        else:
            return 0

# eliminar signo $ y valores menores a 1000
def clean_money(money):
    if money:
        money = [i.replace('$', '') for i in money]
        money = [i.replace(',', '') for i in money]
        money = [i.split('-') for i in money]
        money = [i for i in money if int(i[0]) > 1000]
        return money
    else:
        return 0

# promedio
def average_money(money):
    if money:
        money = [int(i[0]) for i in money]
        return sum(money)/len(money)
    else:
        return 0


a['prom_ingreso'] = df['contenido'].apply(regex_money).apply(clean_money).apply(average_money)